\section{Vorgehensweise, Materialien und Methoden}
\label{sec:konzeption}

Im folgenden Abschnitt wird der Zustand des Projekts bei Übernahme sowie die daraus abgeleiteten Zielsetzungen beschrieben. Darauf aufbauend werden die gewählten technischen Methoden und Materialien erläutert.

Die Projektbearbeitung erfolgte in einem iterativen Entwicklungsprozess, aufgeteilt in die Bereiche Hardware und Software, was eine parallele Umsetzung und kontinuierliche Integrationstests ermöglichte. Zur Versionierung und Dokumentation wurde eine GitHub-Organisation genutzt, die den eigenen Anteil an der Entwicklung transparent nachvollziehbar macht.

\subsection{Mechanischer Aufbau und Konstruktionsprinzipien}

\subsubsection{Analyse des Ausgangsmodells}

Zu Beginn des Projekts wird der einbeinige Krabbelroboter des Legacy-Projekts in Bezug auf Software, Hardware und Funktionsumfang analysiert. Dazu wird besonders die Dokumentationen der Vorgängerprojekte angesehen \cite{vorgängerprojekt}. 

Der aktuelle Zustand des Roboters zum Zeitpunkt der Übernahme ist in Abbildung \ref{fig:crawler_old} dargestellt und ist für die folgenden Abschnitte relevant.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{crawler_old.jpeg}
  \caption{Roboter zum Übernahmezeitpunkt}
  \label{fig:crawler_old}
\end{figure}

\textbf{Mechanische Analyse}

Der Roboter wurde dabei einer mechanischen Strukturanalyse unterzogen. Er bestand zum Zeitpunkt der Übernahme aus einer Basis (Chassis) und einem zweigliedrigen Bein, welche über zwei Servomotoren (Rotationsgelenke) als kinematische Kette verbunden sind.

% Daher konnte die Anzahl $n$ an Freiheitsgraden (DoF) des Roboters mit der Formel von Grübler berechnet werden. Ein Freiheitsgrad ist dabei \glqq jede verbleibende unabhängige Bewegungsfreiheit eines Systems\grqq \ \cite{robotik_scriptum}.
% \begin{align}
%   n = m \cdot (N - 1 - J) + \sum_{i=1}^{J}f_i \noindent \\
%   n = 6 \cdot (3 - 1 - 2) + \sum_{i=1}^{2}1 = 6 \cdot 0 + 2 = 2
% \end{align}
% Dabei ist \glqq $m$ die Anzahl der Freiheitsgrade jedes Starrkörpers ($m = 6$ im dreidimensionalen Raum)\grqq \ \cite{robotik_scriptum}, $N$ die Anzahl der Starrkörper (hier 3: Chassis, Bein, Fuß), $J$ die Anzahl der Gelenke (hier 2) und $f_i$ die Anzahl an Freiheitsgraden des Gelenks $i$. 

% Des Weiteren wurde die Form des Konfigurationsraum des Roboters untersucht. Der Konfigurationsraum beschreibt alle möglichen Positionen und Orientierungen des Roboters im Raum. Mit der Form ist seine topologische Struktur gemeint, sprich wie die möglichen Konfigurationen (alle Konfigurationen zusammen ergeben den Konfigurationsraum) zusammenhängen. Da der Krabbel-Roboter zwei zyklische Rotationsgelenke hat, ergibt sich die Form eines zweidimensionalen Torus $(T^2 = S^1 \times S^1)$, wobei $S^1$ die Menge aller Punkte auf einem Kreis darstellt \cite{robotik_scriptum}. Abbildung \ref{fig:torus} zeigt dies visuell.
% \begin{figure}[h]
%   \centering
%   \includegraphics[width=0.7\textwidth]{torus.png}
%   \caption{Der Konfigurationsraum des Krabbelroboters als Torus, aus \glqq Grundlagen der Robotik\grqq \ \cite{robotik_scriptum}.}
%   \label{fig:torus}
% \end{figure}

% Das Robotersystem entspricht also einem (autonomen) mobilen Roboter mit 2 DoF und einem planaren 2R-Roboterbein. Daraus ließe sich eine Kinematische Modellierung bzw. Simulation erstellen, die allerdings nicht im Rahmen dieser Abschlussarbeit angefertigt wurde. 

\textbf{Funktionsumfang}

Der Funktionsumfang des Roboters beschränkte sich auf die manuelle Steuerung der Motoren über eine graphische Benutzeroberfläche (GUI).

\subsubsection{CAD-gestütztes Design und 3D-Druck} % TO-DO: in "grundlagen" verschieben?

Die Bauteile und das Gehäuse wurden in einem CAD-gestützten Prozess mit \emph{Autodesk Fusion 360} \cite{fusion360} konstruiert. Die digitale Modellierung ermöglichte eine präzise Gestaltung und direkte Überprüfung der Komponenten, die für den Datenaustausch, insbesondere mit Herrn Prof. Dr. Ihme, als standardisierte STEP-Dateien exportiert wurden.

% Der 3D-Druck ermöglichte anschließend eine kostengünstige und ressourcenschonende Fertigung, da durch das additive Verfahren nur das tatsächlich benötigte Material verwendet wurde, was zudem im Vergleich zum Legacy-Projekt Gewicht spart. Dieser Prozess erlaubt eine iterative und flexible Entwicklung ohne komplexe Werkzeuge, was für den Prototypenbau ideal ist (siehe Abbildung \ref{fig:cad_3d_druck}).

Die Fertigung erfolgte mittels Fused Deposition Modeling (FDM), was eine schnelle Iteration der Prototypen ermöglichte. Abbildung \ref{fig:cad_3d_druck} zeigt das gerenderte 3D-Modell sowie ein Foto der oberen Ebene nach dem 3D-Druck.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.45\textwidth]{Vorne-Render.png}
  \hspace{0.05\textwidth}
  \includegraphics[width=0.45\textwidth]{3d-druck.jpg}
  \caption{Gerendertes 3D-Modell aus Fusion 360 (links), obere Ebene nach dem 3D-Druck (rechts)}
  \label{fig:cad_3d_druck}
\end{figure}

\subsubsection{Gestaltungsschwerpunkte}
\label{subsubsec:gestaltungsschwerpunkte}

Ziel der Weiterentwicklung des übernommenen einbeinigen Krabbelroboters war es, ein modular aufgebautes, leichtes und anschaulich gestaltetes System zu schaffen, das sowohl für Demonstrations- als auch Auswertungszwecke geeignet ist. Dabei wurden folgende Anforderungen von uns anfangs festgelegt:

\begin{itemize}
  \item \textbf{Modularität (Basic):} Das Austauschen oder Erweitern zentraler Komponenten (insbesondere des Akkus) sollte erleichtert werden, etwa durch Steck- oder Schraubverbindungen.
  \item \textbf{Offenes Design:} Für Demonstrationszwecke sollten alle Komponenten sichtbar und gut zugänglich montiert sein, um einen schnellen Überblick über das System zu ermöglichen.
  \item \textbf{Verbesserter Schwerpunkt:} Damit das Bein möglichst wenig Last stemmen muss, sollte ein Schwerpunkt nah an der Radachse angestrebt werden.
  \item \textbf{Leichtbauweise:} Ein geringes Gewicht unterstützt die Energieeffizienz und erleichtert die Steuerung durch kleinere Antriebsmotoren.
\end{itemize}

Diese Zielkriterien bildeten die Grundlage für die Auswahl der Bauteile einschließlich Akku und das mechanische Design des weiterentwickelten Roboters.

\subsection{Bau des neuen Crawlers} % verschoben von unten

% Dieses Unterkapitel beschreibt die Hardware des neuen Krabbelroboters, die aus den Komponenten des Vorgängerprojekts übernommen wurde, sowie die neuen Komponenten, die für die Weiterentwicklung ausgewählt wurden. Zusätzlich wird der letztendliche mechanische Aufbau des Crawlers erläutert.
Dieses Unterkapitel beschreibt die übernommenen und neuen Hardwarekomponenten sowie den mechanischen Aufbau des Krabbelroboters.

\subsubsection{Auswahl der Hauptkomponenten}

\textbf{Der Microcontroller}

Der Prozessor des Crawlers ist ein Raspberry Pi 4 Model B, der gleiche Single Board Computer (SBC) wie beim Vorgängerprojekt.

% Zu Anfang unseres Projekts hatten wir lange Zeit Schwierigkeiten, die neuere Ubuntu-Version auf dem SBC zu installieren. Nach langem Debuggen mit verschiedenen Linux-Distributionen, Netzteilen und SD-Karten kamen wir zu dem Schluss, dass das Modell des Vorgängerprojekts zu Schaden gekommen war, seit wir es übernommen hatten, möglicherweise im Transport.

\textbf{Die Sensoren}

Zur Messung von Drehzahlunterschieden an den Rädern werden die zwei Inkrementalgeber des Typs \textit{MEC22} (PWB) \cite{pwb_me16_datasheet_2011} aus dem Legacy-Projekt weiterverwendet. Mit einer Auflösung von 500 Zählimpulsen pro Umdrehung (Counts per Revolution, CPR) und einem Raddurchmesser von \qty{5}{\centi\m} entspricht ein Impuls ca. \qty{0,31}{\milli\m} zurückgelegte Strecke. Dies ermöglicht eine präzise Erfassung kleinster Bewegungen für das Reinforcement Learning. Die Stromversorgung erfolgt direkt über den Raspberry Pi.

\textbf{Die Aktoren}

Für die Beinbewegung wurden Servomotoren vom Typ \textit{Dynamixel XL430-W250-T} (Robotis) \cite{robotis_xl430} eingesetzt. Sie bieten ein gutes Verhältnis von Drehmoment (bis 1{,}5\,Nm) zu Energieverbrauch sowie präzise Positionssteuerung und sind über eindeutige IDs adressierbar.

Die Verbindung zum Steuerrechner erfolgt via TTL-Protokoll über den \textit{U2D2-Connector} \cite{robotis_u2d2}, der per USB an den Raspberry Pi angeschlossen wird. Ein \textit{U2D2 Power Hub} \cite{robotis_u2d2_power_hub} gewährleistet dabei die stabile Spannungsversorgung aller Motoren. Vergleiche dazu auch das nachfolgende Unterkapitel zur Spannunsversorgung. 

\subsubsection{Spannungsversorgung}

Da der alte Akku, ein \textit{XCell LiPo Cracker CAR} \cite{xcell_akku} mit zwei Zellen, \qty{7.4}{\volt} und \qty{5400}{\milli\ampere\hour}, durch sein hohes Gewicht von \qty{310}{\gram} ca. \qty{25}{\percent} des Gesamtgewichts des Roboters ausmachte, wurde ein leichterer Akku gesucht.

Der neu ausgewählte \textit{Gens ace Modellbau-Akkupack (LiPo)} \cite{gens_ace_akku} ist mit seinen ebenfalls \qty{7.4}{\volt} Ausgangsspannung ähnlich aufgebaut, wiegt allerdings nur noch \qty{66}{\gram} und ist deutlich kompakter. Aufgrund des geplanten Einsatzes als Demonstrationsroboter ist auch die damit verbundene geringere Laufzeit kein Problem.

\begin{align*}
t_{\text{Betrieb, alt}} &= \frac{\qty{5400}{\milli\ampere\hour}}{\qty{1070}{\milli\ampere}} \approx \qty{5}{\hour} \\
t_{\text{Betrieb, neu}} &= \frac{\qty{1500}{\milli\ampere\hour}}{\qty{1070}{\milli\ampere}} \approx \qty{1.4}{\hour}
\end{align*}

\qty{1070}{\milli\ampere} sind dabei der maximal gemessene Strom (bei der Bewegung der Motoren) und nicht der Normalzustand.

\subsubsection{Mechanische Umsetzung} % verschoben aus "umsetzung" bzw. "ergebnisse"

Basierend auf den in Abschnitt \ref{subsubsec:gestaltungsschwerpunkte} definierten Zielen wurde die praktische Umsetzung des Chassis eingeleitet.

Zunächst erfolgte eine Recherche der Maße der Bauteile. Auf Basis dieser Daten wurde eine grobe Anordnung in Form einer Handskizze konzipiert, um ein erstes Gefühl für die Platzverhältnisse zu bekommen.

Die Konstruktion wurde in zwei funktionale Ebenen aufgeteilt: 
Eine untere Ebene zur Steuerung der Motoren und eine obere Ebene zur Steuerung der restlichen Bauteile. 
Die Ebenen wurden als separate Körper modelliert, um spätere Anpassungen zu erleichtern.

Der erste 3D-Druck diente zur Kalibrierung der Maße und Überprüfung der Passgenauigkeit. Dabei traten mehrere Fehler auf: 
Einige Schraubenlöcher waren falsch positioniert, die Inkrementalgeber lagen zu nah beieinander, und die Höhe der oberen Griffe erwies sich als zu gering, 
da die Akkumaße zunächst nur geschätzt worden waren.

Da der alte Roboter bis dahin noch softwareseitig genutzt wurde, konnte der mechanische Umbau erst nach Abschluss der entsprechenden Software-Tests (z.\,B. Implementierung des Q-Learnings) erfolgen. 
Anschließend wurde das CAD-Modell überarbeitet und an die gewonnenen Erkenntnisse angepasst.

Nach den Korrekturen konnten alle Bauteile montiert werden.
Der Aufbau des neuen Roboters war damit abgeschlossen und bildete die Grundlage für die weitere softwareseitige Integration.
Abbildung~\ref{fig:crawler_side} zeigt den Krabbelroboter in der Seitenansicht zum Projektabschluss.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{crawler_side.jpeg}
    \caption{Seitliche Ansicht des Krabbelroboters zum Projektabschluss.}
    \label{fig:crawler_side}
\end{figure}

\subsection{Software}

Die Architektur der Crawler-Software, also die Strukturierung des Codes, war einer der wichtigsten Verbesserungspunkte im Vergleich zum Vorgängerprojekt (im Folgenden mit "Legacy-" bezeichnet). 

\subsubsection{Upgrade von ROS 1 zu ROS 2}

Im Vergleich zur Legacy-Codebase portierten wir das Projekt von ROS 1 zu ROS 2. ROS 2 ist zum Zeitpunkt der Arbeit die neueste Major-Version von ROS und unterstützt modernere Versionen des Ubuntu-Betriebssystems. Dadurch konnten wir das Betriebssystem auf dem Raspberry Pi von Ubuntu 18.04 auf Ubuntu 24.04 upgraden. Support für ROS 1 endete außerdem im Mai 2025, während der Laufzeit des Projekts, und die Legacy-installation hätte keine Updates mehr erhalten. Das Upgrade von ROS 1 auf ROS 2 erfordert einige grundlegendere Veränderungen an einem ROS-Projekt, da wir aber ohnehin eine vollständige Überarbeitung der Codebase anstrebten, bedeutete dies praktischerweise keinen zusätzlichen Aufwand. 

% \subsubsection{Developer Experience}

% An vorderer Stelle, sowohl in unserer Priorisierung als auch chronologisch im Projektverlauf, stand auch die Verbesserung der Developer Experience (DX), also eine bewusste Investition in einen reibungslosen Entwicklungsprozess, die mit einer geringeren Fehleranfälligkeit, erhöhtem Komfort und einer gesteigerten Entwicklungsgeschwindigkeit für uns und mögliche nachfolgende Teams einhergeht. 

% Das Legacy-Projekt verfolgte dies bereits mit einem teilweisen Umstieg von Versionskennzeichnungen im Dateinamen zu einer üblichen Versionskontrolle mit Git. Das führten wir weiter und nutzten GitHub zur einfachen Kollaboration. 

% \textbf{Synchronisierung des Quellcodes}

% Im Legacy-Projekt wurde der Programmcode direkt auf dem Raspberry Pi entwickelt, der den Roboter steuert. Wir wollten es ermöglichen, den Code lokal etwa auf dem eigenen Laptop zu editieren, um dabei eine vollwertige Entwicklungsumgebung und andere Tools verwenden zu können, für die die Leistung des Raspberry Pi nicht ausreicht. Außerdem ist dies eine logistische Erleichterung, indem der Pi nun während der Entwicklung und des Betriebs nie zwingend an einen Bildschirm angeschlossen werden muss, und mehrere Personen gleichzeitig daran arbeiten können. 

% Die Synchronisierung des Codes vom Endgerät auf den Pi erfolgt via SSH oder FTP, wobei \texttt{rsync} für eine beschleunigte Synchronisierung durch das Überspringen unveränderter Dateien genutzt wird. Es muss also eine TCP-Verbindung zum Raspberry Pi bestehen, die etwa durch ein lokales Netzwerk, unterwegs durch einen mobilen Hotspot oder auch remote durch eine Portfreigabe hergestellt werden. Eine weitere Option ist die Nutzung eines SSH Reverse Tunnels über einen öffentlichen Anbieter, wodurch lediglich der Internetzugriff durch den Pi und nicht der direkte externe Zugriff auf den SSH-Port des Pi nötig ist, was ggf. unmöglich ist. 

% Die Notwendigkeit einer Internetverbindung ist eine zusätzliche Unannehmlichkeit, die sich jedoch auszahlen dürfte, da der Pi so nicht über einen Bildschirm verfügen muss, indem das Ausführen der ROS-Startbefehle via SSH und der Zugriff auf das Webinterface via HTTP von einem externen Gerät aus geschieht; jederzeit kann stattdessen auch ein Bildschirm und eine Tastatur angeschlossen werden, um Entwicklung und Betrieb wie gewohnt offline zu ermöglichen. 

% \textbf{Vereinfachter Entwicklungszyklus mit Pixi}

% Pixi ist ein Tool zur Softwareentwicklung, das die Verwaltung von Software-Bibliotheken vereinfacht und gleichzeitig als Build-System dient. Bibliotheken und Build-Befehle werden von Pixi in einer Textdatei im Projektverzeichnis gespeichert, sodass die gesamte Entwicklungsumgebung unabhängig vom Hostsystem reproduzierbar ist.

% Der Entwicklungszyklus besteht aus mehreren Schritten, die notwendig sind, um das Programm auf dem Roboter auszuführen:
% \begin{itemize}
% 	\item Der gesamte Quellcode muss auf den Raspberry Pi synchronisiert werden.
% 	\item Die Web-Komponente wird mithilfe von npm, einem Build-Tool für JavaScript, zu einer statischen HTML-Datei gebaut. Da dies auf dem Pi ziemlich lange dauert, kann die Web-Komponente auch zuerst lokal auf dem eigenen Rechner gebaut werden, damit die resultierende HTML-Datei direkt auf den Pi synchronisiert werden kann.
% 	\item Diese HTML-Datei und der Rest des Programms werden mithilfe von ROS zu einem ausführbaren Programm gebündelt.
% 	\item Dieses Programm wird mit einem ROS-Befehl gestartet.
% \end{itemize}

% Mit Pixi konnten wir diesen mehrschrittigen Build-Prozess auf dem Roboter stark vereinfachen. Die einzelnen Schritte sind in Pixi-Befehlen wie \texttt{pixi run upload} oder \texttt{pixi run build-web} definiert, was die Arbeit mit der Codebase wesentlich erleichtert. Im Vergleich zum Vorgängerprojekt ist es außerdem nun leichter, den Build-Prozess zu dokumentieren und zu überliefern. Die Befehle zum Starten des Legacy-Programms mussten uns bei der Projektübergabe noch mündlich mitgeteilt werden, da sie in der Legacy-Codebase nicht festgehalten waren. 

% \textbf{Python Type Hints}

% Ein weiterer Schritt in der Verbesserung der Developer Experience war das Hinzufügen sogenannter Type Hints in der Python-Codebase. Als Programmiersprache mit dynamischen Typen passieren in Python schnell Fehler, wenn Variablen bezüglich ihres Typs falsch verwendet werden.

% Der folgende Python-Code produziert bei seiner Ausführung eine Fehlermeldung wegen falsch verwendeter Typen:

% \begin{minted}{python}
% def greet(s):
% 	# An dieser Stelle entsteht ein "TypeError".
% 	return "Hello " + s

% greet(1)
% \end{minted}

% Diese Fehlermeldung kann wegen der dynamischen Funktionsweise von Python jedoch erst während der Ausführung des Programms entdeckt werden. Type Hints können in einer Codebase hinzugefügt werden, um diese Art der Fehler automatisch zu finden und zu korrigieren, ohne dass eine Ausführung des Programms notwendig ist. Durch entsprechendes Tooling in der Arbeitsumgebung kann dieser Prozess nahtlos in den Entwicklungsprozess integriert werden.

% Im gezeigten Python-Code sähen Type Hints folgendermaßen aus:

% \begin{minted}{python}
% def greet(s: str) -> str:
% 	return "Hello " + s

% greet(1)
% \end{minted}

% Die hinzugefügten Type Hints geben an, dass die Variable \texttt{s} vom Typ String sein muss, sowie, dass die \texttt{greet}-Funktion einen String als Output produziert.

% Wir nutzten mypy \cite{mypy}, um die Nutzung von Type Hints strikt durchzusetzen und von ihnen im Entwicklungsprozess Gebrauch zu machen.

\subsubsection{Architektur der ROS-Nodes}

%- Architektur als Hauptverbesserungspunkt
%- wie es davor war:
%  - fehlende Sortierung zwischen Scripts, Backend-Code, Frontend-Code
%  - zwar verschiedene Nodes, aber trotzdem z.B. Hardware-Steuerung Teil der q_learning-Node etc.
%- wieso die Nodes aufgeteilt sind (anders als zuvor)
%- welche Nodes und Topics existieren, in welchem Verhältnis sie zueinander stehen:
%  - Hardware-Nodes, Web API; crawler_rl_environment, crawler_q_learning; crawler_rl_environment als Interface zwischen RL-Welt und Hardware-Welt
%  -> Diagramm

Die Verbesserung der Codebase zeigt sich vor allem in der Architektur der ROS-Nodes. In der Legacy-Codebase fanden wir initial eine Datei- und Codestruktur vor, die unseren persönlichen stilistischen Präferenzen nicht vollständig entsprach. Insbesondere in der Umsetzung einer für ROS-Applikationen idiomatischen Aufteilung in mehrere Nodes sahen wir Verbesserungspotenzial, da bspw. Code zur konkreten Hardwaresteuerung nicht von der Implementation des Q-Learning-Algorithmus abgegrenzt und teilweise mehrfach dupliziert war. Neben dem zusätzlichen Aufwand, der mit dem Weiterentwickeln einer unbekannten Codebase immer verbunden ist, waren diese stilistischen und architektonischen Differenzen mit der Legacy-Codebase, die nicht schwerwiegend oder unlösbar, aber weitreichendend waren, der Grund für unsere Entscheidung, die Crawler-Software unter Zuhilfenahme des existierenden Codes von Grund auf neu zu schreiben. 

Der neuen Architektur liegt, insbesondere im Vergleich zum Vorgängerprojekt, das Prinzip der Separation of Concerns zugrunde, also die klare Abgrenzung verschiedener Zuständigkeiten, was mit Modularität einhergeht. Dies verbessert die Entwicklung und Wartbarkeit maßgeblich, indem bei der Entwicklung einer Zuständigkeit der umliegende Kontext nur wenig detailliert betrachtet werden muss. 

% Ein Diagramm der im Folgenden beschriebenen neuen Architektur ist im Anhang auf S. \pageref{fig:architekturdiagramm} abgebildet.

\textbf{Hardware-Nodes}

Konkret bedeuteten diese Prinzipien für uns zunächst, die Steuerung einzelner Hardwarekomponenten wie der Inkrementalgeber oder der Motoren zur Zuständigkeit je einer ROS-Node zu machen. In der frühen Entwicklungsphase verwendeten wir, um die konzipierte Funktionsweise der Hardwaresteuerung und später des Zusamenspiels mit dem Webinterface auszuprobieren, eine simple blinkende LED ("Blinker") als Proof of Concept. Im Folgenden ist die Konzeption der Hardware-Nodes an diesem Beispiel, der Node \texttt{crawler\_blinker}, erläutert. Da die LED an einem GPIO-Pin ("General Purpose I/O") des Raspberry Pi angeschlossen ist, übergeben wir den konkreten Pin als Parameter, der in der ROS-Launchdatei noch nach dem Bauen des ROS-Pakets je nach gewünschtem Hardwareaufbau angepasst werden kann. Beim Start stellt die Node außerdem anhand einer Umgebungsvariable fest, ob als zugrundeliegende Implementation die Steuerung der physischen LED über die GPIO-Pins oder eine Mock-LED verwendet werden soll, welche sich nach außen hin wie die reale LED verhält, jedoch keine angeschlossene Hardware voraussetzt, und damit bspw. zur lokalen Entwicklung des Webinterfaces geeignet ist. Für die Operationen, die die LED-Node exponieren soll, werden Subscriptions zu den Topics \texttt{/crawler/blinker/toggle} und \texttt{/crawler/blinker/write} erstellt. Wird dort eine Message mit einem \texttt{Empty}- bzw. \texttt{Boolean}-Wert empfangen -- bei der Motorsteuerung wären das bspw. Zahlenwerte für eine relative Bewegung --, wird die Hardware entsprechend angesteuert. Der aktualisierte Hardwarezustand wird auf dem Topic \texttt{/crawler/blinker/state} veröffentlicht -- bei reinen Sensoren wie den Inkrementalgebern geschieht dies bei jedem neuen Messwert. Die Nodes \texttt{crawler\_motors} und \texttt{crawler\_encoders} zur Steuerung der Motoren bzw. Inkrementalgeber funktionieren nach demselben Prinzip.

\textbf{Web-API-Node}

Zur manuellen Hardwaresteuerung und Anzeige der Hardwarezustände im Webinterface existiert die Node \texttt{crawler\_web\_api}, die hauptsächlich als Adapter zwischen ROS und dem Web fungiert, indem sie den Zugriff auf die ROS-Topics über entsprechende HTTP-Endpoints bereitstellt. So gibt es bspw. den Endpoint \texttt{/api/manual/blinker/toggle} zum Versenden einer Message auf der ROS-Topic \texttt{/crawler/blinker/toggle}. Für die Topics, auf denen die Hardware-Nodes ihren Zustand veröffentlichen, muss ein anderer Mechanismus verwendet werden, da der Datenfluss hier vom Server zum Client verläuft. Bereits im Legacy-Projekt wurden dafür WebSockets verwendet, da sie es dem Server ermöglichen, über eine offen gehaltene TCP-Verbindung aktiv Nachrichten an den Client zu senden. Jedoch wurde dabei nur die Information gesendet, dass ein Update vorliegt, sodass der Client mit einem regulären HTTP-Request reagieren kann, in diesem Fall, um eine gerenderte Diagramm-Grafik des Lernprozesses vom Server zu laden. Das hat den Nachteil, dass durch den zusätzlichenen Request eine Verzögerung entsteht. Es ist außerdem schwieriger, verschiedene Arten von Daten zu übertragen, was vermutlich der Grund dafür ist, dass nur ein Diagramm angezeigt wird, und nicht, wie wir es vorhaben, bspw. weitere Hardwarezustände. Um das zu lösen, übertragen wir die Daten direkt über die WebSocket-Verbindung in einem numerischen Format, um sie anschließend im Webinterface dynamisch in Diagrammen und anderen Visualisierungen rendern zu können. Um die Anzahl offener Verbindungen zu begrenzen, aggregieren wir die Daten mehrerer Topics in einem WebSocket-Endpoint; so werden etwa bei einer Nachricht, die in der Web-API-Node von einer der Hardwarezustand-Topics empfangen wird, die entsprechenden Felder in einer Datenstruktur, die den gesamten Hardwarezustand darstellt, aktualisiert, und anschließend der gesamte Hardwarezustand über den WebSocket-Endpoint gesendet. 

\textbf{Reinforcement-Learning-Nodes}

\textbf{RL-Environment-Node:} Der Teil der Applikation, der für das Reinforcement Learning zuständig ist (siehe Abschnitt~\ref{sec:reinforcement_learning}), besitzt ebenso eine sehr modulare Struktur. Zunächst gibt es die Node \texttt{crawler\_rl\_environment}, die den Reinforcement-Learning-Prozess überwacht und verwaltet. Außerdem übersetzt sie, entsprechend ihrer Benennung, die über die Topics gelesenen Hardwarezustände in ein für den RL-Algorithmus passendes Format eines Environments im Sinne des RL-Frameworks; ebenso wird der Reward anhand der Inkrementalgeber-Daten bestimmt. Der Reinforcement-Learning-Zyklus wird von der Environment-Node ausgehend gesteuert: Nachdem sie eine Nachricht zum Starten empfangen hat, sendet sie das erste Environment (und keinen Reward) auf \texttt{/crawler/rl/state\_reward} und wartet auf die Antwort der RL-Node auf \texttt{/crawler/rl/action}. Entsprechend der gewünschten Aktion werden Nachrichten zur Hardwaresteuerung gesendet, und das nächste Environment und der nächste Reward werden in einem fortlaufenden Prozess gesendet.
% TODO: "Reinforcement-Learning-Zyklus" bessere Formulierung?

\textbf{RL-Node:} Der Reinforcement-Learning-Algorithmus ist in der RL-Node implementiert, welche die oben genannten Topics Environment und Reward von der Environment-Node empfängt bzw. eine Aktion sendet. Bisher ist nur ein konkreter Algorithmus implementiert, in Zukunft sind aber auch verschiedene Implementationen denkbar; da die Schnittstelle mit der Environment-Node abstrakt gehalten ist, lässt sich die RL-Node also beliebig durch andere Implementationen ersetzen. Daher wird die RL-Node erst bei Bedarf z.\,B. über das Webinterface von der Web-API-Node mit den eingestellten Parametern gestartet.

Um den Crawler als Demonstrationsroboter geeignet zu machen, möchten wir den internen Zustand des RL-Algorithmus anschaulich visualisieren. Dazu senden die RL-Environment-Node und die RL-Node ihren internen Zustand, der von der Web-API-Node aggregiert und auf einem WebSocket-Endpoint veröffentlicht wird. 

\subsubsection{Webinterface}

Bereits das unmittelbare Vorgängerprojekt hatte die Verbesserung des Crawlers hinsichtlich seiner Eignung zu Demonstrationszwecken zum Ziel, indem ein simples Webinterface zur manuellen Steuerung sowie zum Starten und Überwachen des Reinforcement Learning implementiert wurde. Wir führten diesen Gedanken weiter, indem wir ein neues Webinterface von Grund auf neu entwickelten. Da die Verwendung des Crawlers zu Demonstrationszwecken die für unser Projekt am relevantesten erscheinende Anwendung ist, investierten wir hierbei auch über reines Funktionieren hinaus in eine flüssige und ansehnliche Benutzererfahrung. 

Neben einer Home-Seite mit einführenden Informationen zum Crawler und Links zur GitHub-Seite hat das Webinterface zwei Hauptfunktionen. Zunächst ist das die manuelle Kontrolle (\textbf{Manual Control}) aller Hardwarekomponenten, d. h. Steuerung der Motoren und Darstellung der von den Inkrementalgebern eingelesenen Daten, was bspw. zum Debuggen in einem früheren Stadium des Projekts sehr praktisch war und weiterhin sein wird. Zur Veranschaulichung sind die UI-Elemente den physischen Komponenten visuell nachempfunden, und der aktuelle Zustand wird sowohl numerisch als auch durch eine entsprechende Animation der abgebildeten Komponenten dargestellt. Da bei einer Demonstration der Bildschirm womöglich auf eine solche Weise projiziert wird, dass dem Mauszeiger, sofern es einen gibt, nicht leicht zu folgen ist, werden Interaktionen mit den Bedienflächen durch ein rotes Aufblinken klar verdeutlicht. Das \textbf{RL Control} bietet eine Benutzeroberfläche zum Konfigurieren und Starten des Reinforcement Learning zur Steuerung des Roboters. Im laufenden Betrieb des RL-Algorithmus werden außerdem in Echtzeit Informationen zum aktuellen internen Zustand angezeigt, die möglichst anschaulich visualisiert werden, sodass man als Publikum oder Forschende etc. die Funktionsweise des Demonstrationsroboter leicht nachvollziehen kann. So ist erstens der Zustand des RL-Environments mit dem letzten Reward (in farblicher Kennung entsprechend dem Vorzeichen), der zuletzt gewählten Aktion und einem Diagramm visualisiert, das den Lernfortschritt, d. h. die insgesamt zurückgelegte Strecke, über die Zeit darstellt und ebenso in Echtzeit angepasst wird. Zweitens wird die Q-Table als interner Zustand der RL-Node offengelegt. Dabei werden die Tablellenzellen entsprechend ihrem Wert eingefärbt, um die Gewichtung zu verdeutlichen; die Anpassung der Q-Table, die nach jedem Schritt vorgenommen wird, wird durch eine kurze Hervorhebung zusätzlich angezeigt. 

Eine später hinzugefügte Bedienoberfläche ist die Möglichkeit, in die Auswahl der nächsten Aktion durch den Q-Learning-Algorithmus manuell einzugreifen, was es er\-möglicht, den Lernprozess zur besseren Nachvollziehbarkeit schrittweise ablaufen zu lassen. Zuletzt ist noch die Möglichkeit essenziell, trainierte Modelle, d. h. den Inhalt einer Q-Table, exportieren und bei Starten des Q-Learning erneut importieren zu können. Dies geschieht in einem serialisierten Textformat, das beliebig lokal gespeichert werden kann. Diese Option erlaubt es, einen erfolgreichen Lernvorgang festzuhalten und zu einem späteren Zeitpunkt zu nutzen. 

Für die Umsetzung des Backends verwenden wir den simplen Python-Webserver \emph{Flask} \cite{flask}, der auch bereits im Vorgängerprojekt verwendet wurde. Das Webinterface ist mit der UI-Library \emph{React} \cite{react} implementiert, welche einen modernen komponentenbasierten Workflow bietet und von Grund auf reaktiv ist, was die Anzeige der Echtzeitdaten maßgeblich erleichtert. Für eine moderne UI-Entwicklung verwenden wir \emph{Tailwind CSS} \cite{tailwindcss} als Styling-Framework, \emph{React Router} \cite{reactrouter} als React-Framework und \emph{Chart.js} \cite{chartjs} für dynamische Diagramme.

% Im Anhang, S. \pageref{fig:webinterface_screenshots}f, sind einige Screenshots abgebildet.